---
title: "Infant Asphyxiation Mortality Modeling"
author: "Daniel P. Riggins, MD"
date: "11/1/2021"
output: html_document
---

This modeling analysis will seek to predict infant asphyxiation deaths in Chicagoland census tracts using a variety of census-level predictor variables, many of which are derived from the CDC's [Social Vulnerability Index (SVI)](https://seandavi.github.io/sars2pack/reference/cdc_social_vulnerability_index.html).

# Set Up

## Load needed libraries:

```{r message=FALSE, warning=FALSE}
library(tidyverse)
library(DataExplorer)
library(correlation)
library(vcd)
library(tidycensus)
library(sf)
library(see)
library(performance)
```

## Import the data:

```{r}
raw <- readxl::read_xlsx("data/finaldataforanalysis3_110221.xlsx")
```

## Get census tract populations and spatial features:

```{r echo=TRUE, results=FALSE, message=TRUE, warning=TRUE}
# tidycensus::load_variables(2019, "acs5", cache = TRUE) %>% view()
# "B01003_001" : Total Population
# "B01001_003" : All Males Under 5 yrs
# "B01001_027" : All Females Under 5 yrs
# "B06001_002" : All Under 5 yrs

enriched <-
    get_acs(
        geography = "tract",
        variables = "B06001_002",
        state = "IL",
        geometry = TRUE,
        cache_table = TRUE
    ) %>%
    filter(GEOID %in% raw$FIPS) %>%
    mutate(
        FIPS = as.numeric(GEOID),
        centroid = st_centroid(geometry)
    ) %>%
    select(
        FIPS,
        population = estimate,
        centroid
    ) %>%
    full_join(raw)
```

```{r}
glimpse(enriched)
```
## Split data into training and test sets:

The training set will be used for model development and iterative model performance comparisons via resampling. The testing set will be used for final model validation. See [Ch. 5](https://www.tmwr.org/splitting.html) of @kuhnTidyModeling for more details on the rationale.

```{r}
set.seed(324)
split <- rsample::initial_split(enriched, prop = 0.75)
training_geom <- rsample::training(split)
testing_geom <- rsample::testing(split)
training <- training_geom %>% as_tibble() %>% select(-centroid, -geometry)
testing <- testing_geom %>% as_tibble() %>% select(-centroid, -geometry)
```

# First Pass Exploration

## Summarize the primary outcome (count of asphyxia deaths per census tract):

```{r}
table(training$Count_Asphyxia)
```
## Visualize the primary outcome:

```{r}
plot_histogram(training$Count_Asphyxia)
```

The distribution of outcome data seems consistent with theoretical distributions like the Poisson or negative binomial.

## Visualize the outcome on a map:

```{r}
tmap_mode("view")

tm_shape(enriched) +
    tm_polygons("Count_Asphyxia")
```


```{r}

asphyxia.sp <- enriched %>%
    select(Count_Asphyxia) %>%
    as_Spatial()

weighted_list <- 
    spdep::poly2nb(asphyxia.sp, queen = TRUE) %>%
    spdep::nb2listw(style = "W")

asphyxia_lag <- spdep::lag.listw(weighted_list, asphyxia.sp$Count_Asphyxia)

plot( asphyxia_lag ~ asphyxia.sp$Count_Asphyxia, pch=20, asp=1, las=1)
```


```{r}
MC <- moran.mc(asphyxia.sp$Count_Asphyxia, weighted_list, nsim=599)

MC
```


## Visualize raw predictors:

```{r}
plot_histogram(select(training, 2, 4:32))
```



# Predictor selection

## Explore correlations

When choosing predictors for our model, we want variables that are as highly correlated with `Count_Asphyxia` as possible, while minimizing the potential for multicollinearity.

Let's start by generating a correlation matrix:

```{r}
correlations <- training %>%
    select(-FIPS) %>%
    relocate(Count_Asphyxia, .before = population) %>%
    corrr::correlate()

correlations
```

Now filter for variables that have at least a weak correlation (> 0.20) with `Count_Asphyxia`:

```{r}
asphyxia_correlations <-
    correlations %>%
    filter(abs(Count_Asphyxia) > 0.20) %>%
    arrange(desc(abs(Count_Asphyxia)))

asphyxia_correlations
```

`publicinsurance` has (just barely) the strongest correlation with `Count_Asphyxia`. Let's visualize the relationship:

```{r}
plot(cor_test(training, "Count_Asphyxia", "publicinsurance"))
```

In order to minimize multicollinearity, let's select for variables that still have some degree of correlation with `Count_Asphyxia`, but have no more than weak correlation (< 0.5) with `publicinsurance`:

```{r}
asphyxia_correlations %>%
    filter(abs(Count_Asphyxia) > 0.20) %>%
    filter(abs(publicinsurance) < 0.5)
```

This just leaves the count of opioid deaths per census tract:

```{r}
plot(cor_test(training, "Count_Asphyxia", "Count_OPIOID_Death"))
```

There's a large outlier of many opioid deaths in an area with no asphyxiation deaths, but otherwise, there does seem to be a positive trend.

To fill out our modeling, we wil also try another four variables that correlate with `Count_Asphyxia`. These being `white`, `incomegt75`, `SVI_HouseholdCompositionDisability`, and `PE_marriedfemales`. I left out `black` and `private` because these are definitely co-linear with `white` and `publicinsurance` respectively. Those with a discerning eye will note that earlier I added census tract population count to our data set as a potential control variable, but there does not seem to be a meaningful correlation between `Count_Asphyxia` and `population`.

Here are summary statistics of our candidate predictors:

```{r}
training %>%
    select(
        Count_OPIOID_Death, 
        publicinsurance, 
        white, 
        incomegt75, 
        SVI_HouseholdCompositionDisability, 
        PE_marriedfemales
    ) %>%
    summary()
```

# Pre-processing

As alluded to earlier, we will be using Poisson regression as the initial model of consideration. According to [Appendix A](https://www.tmwr.org/pre-proc-table.html) of @kuhnTidyModeling, the recommended pre-processing steps for Poisson regression are dummy variable generation, removal of columns with single unique values, imputation for missing data, de-correlation, and possibly transformation.

Many of these steps are not necessary for our data set. Because we do not have categorical predictors, we do not need to perform dummy variable generation or removal of columns with single unique variables. Because we do not have any missing data, we do not need to perform imputation. That leaves transformation and de-correlation.

## Transformation

### Centering

For ease of intercept interpretation, we will center the variables whose minimums are greater than zero:

```{r}
glm_training <-
    training %>%
    select(
        Count_Asphyxia, 
        publicinsurance, 
        Count_OPIOID_Death,
        white, 
        incomegt75, 
        SVI_HouseholdCompositionDisability, 
        PE_marriedfemales
    ) %>%
    mutate(
        publicinsurance_cen = publicinsurance - mean(publicinsurance),
        incomegt75_cen = incomegt75 - mean(incomegt75),
        SVI_HouseholdCompositionDisability_cen = SVI_HouseholdCompositionDisability - mean(SVI_HouseholdCompositionDisability),
        PE_marriedfemales_cen = PE_marriedfemales - mean(PE_marriedfemales)
    ) %>%
    select(-c(publicinsurance,incomegt75, SVI_HouseholdCompositionDisability, PE_marriedfemales))
```

## De-Correlation

While selecting our variables, we have done our best to minimize multicollinearity. However, eventually this analysis will also include principal component analysis as a means to potentially boost model performance.

# Model Development

## Develop multivariate Poisson regression models

Let's build up 6 models that use step-wise additions of the predictors of interest. We'll select a final model, by comparing their respective performance metrics:

```{r}
poisson_1 <- glm(Count_Asphyxia ~ publicinsurance_cen, family = poisson(), data = glm_training)

poisson_2 <- glm(Count_Asphyxia ~ publicinsurance_cen + Count_OPIOID_Death, family = poisson(), data = glm_training)

poisson_3 <- glm(Count_Asphyxia ~ publicinsurance_cen + Count_OPIOID_Death + white, family = poisson(), data = glm_training)

poisson_4 <- glm(Count_Asphyxia ~ publicinsurance_cen + Count_OPIOID_Death + white + incomegt75_cen, family = poisson(), data = glm_training)

poisson_5 <- glm(Count_Asphyxia ~ publicinsurance_cen + Count_OPIOID_Death + white + incomegt75_cen + SVI_HouseholdCompositionDisability_cen, family = poisson(), data = glm_training)

poisson_6 <- glm(Count_Asphyxia ~ publicinsurance_cen + Count_OPIOID_Death + white + incomegt75_cen + SVI_HouseholdCompositionDisability_cen + PE_marriedfemales_cen, family = poisson(), data = glm_training)
```

```{r}
compare_performance(poisson_1, poisson_2, poisson_3, poisson_4, poisson_5, poisson_6) %>% print_html()
```

Eye-balling the results, `poisson_4` seems like a good candidate since it has the best AIC value (best relative fit while adjusting for number of predictors) and is tied for best adjusted R-squared (quantification of fit) and RMSE (precision). Let's see if our intuition matches with a ranking algorithm:

```{r}
compare_performance(poisson_1, poisson_2, poisson_3, poisson_4, poisson_5, poisson_6, rank = TRUE) %>% print_html()
```

It does! Let's visualize the fit with a rootogram:

```{r}
get_pred_freq_vector <- function(model) {
    pred_tbl <- 
        as_tibble(round(model$fitted.values)) %>%
        group_by(value) %>%
        summarize(n = n())
    
    diff <- length(table(model$y)) - length(pred_tbl$n)
    
    if(diff == 0){
        pred_freq_vector <- pred_tbl$n
    } else if(diff > 0) {
        pred_freq_vector <- c(pred_tbl$n, rep(0, diff))
    }
    
    return(pred_freq_vector)
}

poisson_4_pred_freq <-get_pred_freq_vector(poisson_4)

vcd::rootogram(table(poisson_4$y), poisson_4_pred_freq)
```

We see that our Poisson model does a decent job approximating counts of 0 and 1 for `Count_Asphyxia`, but under-counts anything above 1.

This problem is called overdispersion and is not uncommon when modeling discrete count data. Overdispersion means that the observed data shows more variability than expected from the assumed distribution. Let's do a formal test for it:

```{r}
check_overdispersion(poisson_4)
```
While not terrible, overdispersion is indeed present. We will likely get a better fit using a different assumed distribution of the outcome.

For completeness, let's check other indicators for validity of our model assumptions:

```{r}
check_model(poisson_4)
```

We see here we also have issues with heteroskedascity, with influential observations, and with normality of the residuals. This provides further evidence that we should explore other means of modeling the outcome.

