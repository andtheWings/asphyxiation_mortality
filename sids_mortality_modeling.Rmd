---
title: "Infant Asphyxiation Mortality Modeling"
author: "Daniel P. Riggins, MD"
date: "11/1/2021"
output: html_document
---

This modeling analysis will seek to predict the number of Sudden Infant Death Syndrome (SIDS)-related deaths in Chicagoland census tracts using a variety of census-level predictor variables, many of which are derived from the CDC's [Social Vulnerability Index (SVI)](https://seandavi.github.io/sars2pack/reference/cdc_social_vulnerability_index.html).

# Set Up

## Load needed libraries:

```{r message=FALSE, warning=FALSE}
library(tidyverse)
library(DataExplorer)
library(correlation)
library(vcd)
library(tidycensus)
library(sf)
library(see)
library(performance)
library(tmap)
library(spdep)
library(tidymodels)
tidymodels_prefer()
```

## Import the data:

```{r}
raw <- readxl::read_xlsx("data/finaldataforanalysis3_211102.xlsx")
```

## Get census tract populations and spatial features:

```{r echo=TRUE, results=FALSE, message=TRUE, warning=TRUE}
# tidycensus::load_variables(2019, "acs5", cache = TRUE) %>% view()
# "B01003_001" : Total Population
# "B01001_003" : All Males Under 5 yrs
# "B01001_027" : All Females Under 5 yrs
# "B06001_002" : All Under 5 yrs

get_coords_and_pop <- function(tibble) {
    acs_payload <- 
        get_acs(
            geography = "tract",
            variables = "B06001_002",
            state = "IL",
            geometry = TRUE,
            cache_table = TRUE
        ) %>%
        filter(.data[["GEOID"]] %in% tibble[["FIPS"]]) 
    
    final <-
        acs_payload %>%
        mutate(
            FIPS = as.numeric(.data[["GEOID"]]),
            centroid = st_centroid(st_geometry(acs_payload)),
            longitude = st_coordinates(.data[["centroid"]])[,1],
            latitude = st_coordinates(.data[["centroid"]])[,2],
            pop_under_five = estimate
        ) %>%
        select(
            FIPS,
            pop_under_five,
            longitude,
            latitude
        ) %>%
        full_join(tibble) %>%
        mutate(est_proportion_SIDS = .data[["Count_Asphyxia"]] / (.data[["pop_under_five"]] / 5))
    
    return(final)
}

enriched <- get_coords_and_pop(raw)

df <- enriched %>%
    as_tibble() %>%
    select(-geometry)

```

## Generate spatially-clustered folds of data for cross-validation

```{r}
set.seed(326)

folds <- 
    spatialsample::spatial_clustering_cv(
        data = as_tibble(enriched),
        coords = c("latitude", "longitude"),
        v = 10 # Number of folds to generate
    )

# This function derived from vignette for the {spatialsample} pkg
# It visualizes the folds you have generated
plot_splits <- function(split) {
    p <- analysis(split) %>%
        mutate(analysis = "Analysis") %>%
        bind_rows(assessment(split) %>%
                      mutate(analysis = "Assessment")) %>%
        ggplot(aes(longitude, latitude, color = analysis)) + 
        geom_point(alpha = 0.5) +
        labs(color = NULL)
    print(p)
}

walk(folds$splits, plot_splits)
```

# First Pass Exploration

##

```{r}
plot_histogram(df$est_proportion_SIDS)
```


```{r}
df %>% 
  count(est_proportion_SIDS == 0) %>% 
  mutate(prop = n / sum(n))
```



## Summarize the primary outcome (count of asphyxia deaths per census tract):

```{r}
table(enriched$Count_Asphyxia)
```
## Visualize the primary outcome:

```{r}
plot_histogram(enriched$Count_Asphyxia)
```

```{r}
plot_histogram(filter(enriched, percent_SIDS > 0)[["percent_SIDS"]])
```


The distribution of outcome data seems consistent with theoretical distributions like the Poisson or negative binomial.

## Visualize the outcome as percentage of estimated population of children under age 1

## Visualize the outcome on a map:

```{r}

test <- enriched %>%
    filter(Count_Asphyxia > 0) %>%
    mutate(percentile = percent_rank(percent_SIDS))

tmap_mode("view")

tm_shape(test) +
    tm_polygons("percentile")
```


```{r}
asphyxia.sp <- enriched %>%
    select(Count_Asphyxia) %>%
    as_Spatial()

weighted_list <- 
    spdep::poly2nb(asphyxia.sp, queen = TRUE) %>%
    spdep::nb2listw(style = "W")

asphyxia_lag <- spdep::lag.listw(weighted_list, asphyxia.sp$Count_Asphyxia)

plot( asphyxia_lag ~ asphyxia.sp$Count_Asphyxia, pch=20, asp=1, las=1)
```


```{r}
MC <- moran.mc(asphyxia.sp$Count_Asphyxia, weighted_list, nsim=599)

MC
```


## Visualize raw predictors:

```{r}
plot_histogram(select(training, 2, 4:32))
```



# Predictor candidate selection

## Explore correlations

When choosing predictors for our model, we want variables that are as highly correlated with `Count_Asphyxia` as possible, while minimizing the potential for multicollinearity.

```{r}
tmwr_cols <- colorRampPalette(c("#91CBD765", "#CA225E"))
enriched %>%
    as_tibble() %>%
    select(-FIPS, -longitude, -latitude, -geometry) %>%
    cor() %>%
    corrplot::corrplot(col = tmwr_cols(200), tl.col = "black")
```


Let's start by generating a correlation matrix:

```{r}
correlations <- training %>%
    select(-FIPS) %>%
    relocate(Count_Asphyxia, .before = population) %>%
    corrr::correlate()

correlations
```




Now filter for variables that have at least a weak correlation (> 0.20) with `Count_Asphyxia`:

```{r}
asphyxia_correlations <-
    correlations %>%
    filter(abs(Count_Asphyxia) > 0.20) %>%
    arrange(desc(abs(Count_Asphyxia)))

asphyxia_correlations
```

`publicinsurance` has (just barely) the strongest correlation with `Count_Asphyxia`. Let's visualize the relationship:

```{r}
plot(cor_test(training, "Count_Asphyxia", "publicinsurance"))
```

In order to minimize multicollinearity, let's select for variables that still have some degree of correlation with `Count_Asphyxia`, but have no more than weak correlation (< 0.5) with `publicinsurance`:

```{r}
asphyxia_correlations %>%
    filter(abs(Count_Asphyxia) > 0.20) %>%
    filter(abs(publicinsurance) < 0.5)
```

This just leaves the count of opioid deaths per census tract:

```{r}
plot(cor_test(training, "Count_Asphyxia", "Count_OPIOID_Death"))
```

There's a large outlier of many opioid deaths in an area with no asphyxiation deaths, but otherwise, there does seem to be a positive trend.

To fill out our modeling, we wil also try another four variables that correlate with `Count_Asphyxia`. These being `white`, `incomegt75`, `SVI_HouseholdCompositionDisability`, and `PE_marriedfemales`. I left out `black` and `private` because these are definitely co-linear with `white` and `publicinsurance` respectively. Those with a discerning eye will note that earlier I added census tract population count to our data set as a potential control variable, but there does not seem to be a meaningful correlation between `Count_Asphyxia` and `population`.

Here are summary statistics of our candidate predictors:

```{r}
training %>%
    select(
        Count_OPIOID_Death, 
        publicinsurance, 
        white, 
        incomegt75, 
        SVI_HouseholdCompositionDisability, 
        PE_marriedfemales
    ) %>%
    summary()
```

# Pre-processing

As alluded to earlier, we will be using Poisson regression as the initial model of consideration. According to [Appendix A](https://www.tmwr.org/pre-proc-table.html) of @kuhnTidyModeling, the recommended pre-processing steps for Poisson regression are dummy variable generation, removal of columns with single unique values, imputation for missing data, de-correlation, and possibly transformation.

Many of these steps are not necessary for our data set. Because we do not have categorical predictors, we do not need to perform dummy variable generation or removal of columns with single unique variables. Because we do not have any missing data, we do not need to perform imputation. That leaves transformation and de-correlation.

## Transformation

### Centering

For ease of intercept interpretation, we will center the variables whose minimums are greater than zero:

```{r}
glm_training <-
    training %>%
    select(
        FIPS,
        Count_Asphyxia, 
        publicinsurance, 
        Count_OPIOID_Death,
        white, 
        incomegt75, 
        SVI_HouseholdCompositionDisability, 
        PE_marriedfemales
    ) %>%
    mutate(
        publicinsurance_cen = publicinsurance - mean(publicinsurance),
        incomegt75_cen = incomegt75 - mean(incomegt75),
        SVI_HouseholdCompositionDisability_cen = SVI_HouseholdCompositionDisability - mean(SVI_HouseholdCompositionDisability),
        PE_marriedfemales_cen = PE_marriedfemales - mean(PE_marriedfemales)
    )
```

## De-Correlation

While selecting our variables, we have done our best to minimize multicollinearity. However, eventually this analysis will also include principal component analysis as a means to potentially boost model performance.

```{r}
umap_recipe <- 
    recipe(Count_Asphyxia ~ ., data = df) %>%
    update_role(FIPS, new_role = "ID") %>%
    update_role(
        longitude, latitude, est_percent_SIDS,
        new_role = "not_in_model"
    ) %>%
    step_normalize(all_numeric_predictors()) %>%
    embed::step_umap(all_predictors())
    
umap_prep <- prep(umap_recipe)
    
umap_bake <- bake(umap_prep, new_data = df)

umap_bake %>%
  ggplot(aes(UMAP1, UMAP2)) +
  geom_point(alpha = 0.5, size = 2)+
  labs(color = NULL) +
  theme_minimal()

poisson_recipe <-
    recipe(Count_Asphyxia ~ UMAP1 + UMAP2, data = umap_bake)

poisson_model <-
    poissonreg::poisson_reg()

umap_poisson_workflow <-
    workflow() %>%
    add_recipe(poisson_recipe) %>%
    add_model(poisson_model) %>%
    fit(umap_bake)

umap_poisson_predict <- 
    predict(umap_poisson_workflow, umap_bake) %>%
    bind_cols(.obs = umap_bake$Count_Asphyxia)


```


# Model Development

Let's build up 6 models that use step-wise additions of the predictors of interest. We'll select a final model, by comparing their respective performance metrics:

```{r}
formulas <- list(
        one_var = Count_Asphyxia ~ publicinsurance_cen,
        two_vars = Count_Asphyxia ~ publicinsurance_cen + Count_OPIOID_Death,
        three_vars = Count_Asphyxia ~ publicinsurance_cen + Count_OPIOID_Death + white,
        four_vars = Count_Asphyxia ~ publicinsurance_cen + Count_OPIOID_Death + white + incomegt75_cen,
        five_vars = Count_Asphyxia ~ publicinsurance_cen + Count_OPIOID_Death + white + incomegt75_cen + SVI_HouseholdCompositionDisability_cen,
        six_vars = Count_Asphyxia ~ publicinsurance_cen + Count_OPIOID_Death + white + incomegt75_cen + SVI_HouseholdCompositionDisability_cen + PE_marriedfemales_cen
)

```

## Develop Poisson regression models

Train poisson models on the formulas:

```{r}
poisson_models <- map(
    .x = formulas,
    .f = ~ glm(formula = .x, family = poisson(), data = glm_training)
)
```

```{r}
compare_performance(poisson_models) %>% print_html()
```

Eye-balling the results, `poisson_4` seems like a good candidate since it has the best AIC value (best relative fit while adjusting for number of predictors) and is tied for best adjusted R-squared (quantification of fit) and RMSE (precision). Let's see if our intuition matches with a ranking algorithm:

```{r}
compare_performance(poisson_models, rank = TRUE) %>% print_html()
```

It does! Let's visualize the fit with a rootogram:

```{r}
make_rootogram <- function(model) {
    
    if(any(class(model) %in% "glm")){
        predictions <- 
            as_tibble(round(model$fitted.values)) %>%
            group_by(value) %>%
            summarize(n = n()) %>%
            pull("n")
        observations <-
            model$y
    } else if(any(class(model) %in% "tbl_df")) {
        predictions <-
            as_tibble(round(model$.pred)) %>%
            group_by(value) %>%
            summarize(n = n()) %>%
            pull("n")
        observations <- model$.obs
    }
    
    diff <- length(table(observations)) - length(predictions)
    print(diff)

    if(diff > 0){
        predictions <- c(predictions, rep(0, diff))
    }
    
    return(vcd::rootogram(table(observations), predictions))
}

make_rootogram(poisson_models[[4]])

make_rootogram(umap_poisson_predict)
```

We see that our Poisson model does a decent job approximating counts of 0 and 1 for `Count_Asphyxia`, but under-counts anything above 1.

This problem is called overdispersion and is not uncommon when modeling discrete count data. Overdispersion means that the observed data shows more variability than expected from the assumed distribution. Let's do a formal test for it:

```{r}
check_overdispersion(poisson_4)
```
While not terrible, overdispersion is indeed present. We will likely get a better fit using a different assumed distribution of the outcome.

For completeness, let's check other indicators for validity of our model assumptions:

```{r}
check_model(poisson_4)
```

We see here we also have issues with heteroskedascity, with influential observations, and with normality of the residuals. This provides further evidence that we should explore other means of modeling the outcome.

## Develop Quasi-Poisson Models

```{r}
qpoisson_2 <- glm(Count_Asphyxia ~ publicinsurance_cen + Count_OPIOID_Death, quasipoisson(), data = glm_training)

qpoisson_3 <- glm(Count_Asphyxia ~ publicinsurance_cen + Count_OPIOID_Death + white, family = quasipoisson(), data = glm_training)

qpoisson_4 <- glm(Count_Asphyxia ~ publicinsurance_cen + Count_OPIOID_Death + white + incomegt75_cen, family = quasipoisson(), data = glm_training)

qpoisson_5 <- glm(Count_Asphyxia ~ publicinsurance_cen + Count_OPIOID_Death + white + incomegt75_cen + SVI_HouseholdCompositionDisability_cen, family = quasipoisson(), data = glm_training)
```

```{r}
compare_performance(qpoisson_2, qpoisson_3, qpoisson_4, qpoisson_5, rank = TRUE) %>% print_html()
```

```{r}
qpoisson_4_pred_freq <-get_pred_freq_vector(qpoisson_4)

vcd::rootogram(table(qpoisson_4$y), qpoisson_4_pred_freq)
```

```{r}
check_model(qpoisson_4)
```

## Develop Negative Binomial Model

```{r}
binom_3 <- MASS::glm.nb(Count_Asphyxia ~ publicinsurance_cen + Count_OPIOID_Death + white, link = log, data = glm_training)

binom_4 <- MASS::glm.nb(Count_Asphyxia ~ publicinsurance_cen + Count_OPIOID_Death + white + incomegt75_cen, link = log, data = glm_training)

binom_5 <- MASS::glm.nb(Count_Asphyxia ~ publicinsurance_cen + Count_OPIOID_Death + white + incomegt75_cen + SVI_HouseholdCompositionDisability_cen, link = log, data = glm_training)
```

```{r}
compare_performance(binom_3, binom_4, binom_5, rank = TRUE) %>% print_html()
```

```{r}
make_rootogram(binom_4)
```


```{r}
check_model(binom_4)
```

```{r}
compare_performance(binom_4, poisson_4, rank = TRUE) %>% print_html()
```

### Export model predictions and observations

```{r}
neg_binomial_export <-
    bind_cols(
        glm_training[,c("FIPS", "Count_Asphyxia", "publicinsurance", "Count_OPIOID_Death", "white", "incomegt75")],
        raw_predictions = binom_4$fitted.values,
        rounded_predictions = round(binom_4$fitted.values)
    ) %>%
    relocate(raw_predictions, rounded_predictions, .after = Count_Asphyxia)

xlsx::write.xlsx(neg_binomial_export, "data/negative_binomial_prediction_model_2021_11_23.xlsx")
```


Data Dictionary:

- FIPS: Census Tract ID
- Count_Asphyxia: Count of asphyxia-related deaths in that census tract (observed outcome)
- raw_predictions: Output of prediction model for counts of asphyxia-related deaths
- rounded_predictions: The raw predictions rounded into discrete count values
- publicinsurance: Percent of people in that census tract on public health insurance (predictor)
- Count_OPIOID_Death: Count of opioid-related deaths in that census tract (predictor)
- white: Percent of people in that census tract who self-identify as white (predictor)
- incomegt75: Percent of people in that census tract with income greater than the 75th percentile (predictor)

## Try out zero-inflated models

```{r}
formula_4 <- Count_Asphyxia ~ publicinsurance_cen + Count_OPIOID_Death + white + incomegt75_cen

zip_4 <- pscl::zeroinfl(formula_4, data = glm_training)

zinb_4 <- pscl::zeroinfl(formula_4, dist = "negbin", data = glm_training)
```

```{r}
compare_performance(poisson_4, binom_4, zip_4, zinb_4) %>% print_html()
```

## Develop Random Forest Model

```{r}
preds <- c("publicinsurance_cen", "Count_OPIOID_Death", "white", "incomegt75_cen")

library(tidymodels)

rf_pred_obs <- 
    rand_forest(mode = "regression") %>%
    set_engine("ranger") %>%
    fit_xy(
        x = glm_training[, preds],
        y = glm_training$Count_Asphyxia
     ) %>%
    predict(glm_training) %>%
    bind_cols(.obs = glm_training$Count_Asphyxia)
```

```{r}
rf_pred_tbl <- 
        as_tibble(round(rf_preds$.pred)) %>%
        group_by(value) %>%
        summarize(n = n())

rf_pred_freq_vector <- c(rf_pred_tbl$n, rep(0, 2))

vcd::rootogram(table(glm_training$Count_Asphyxia), rf_pred_freq_vector)
```

