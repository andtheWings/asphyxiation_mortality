---
title: "Modeling Counts of Sudden Infant Death Syndrome in Census Tracts of Cook County, IL"
author: "Daniel P. Hall Riggins, MD"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: html_document
---

This analysis seeks to model the number of cases of Sudden Infant Death Syndrome (SIDS)-related deaths in Cook County, IL census tracts using a variety of census-level ecologic variables, some of which are derived from the CDC's [Social Vulnerability Index (SVI)](https://seandavi.github.io/sars2pack/reference/cdc_social_vulnerability_index.html). 

```{r message=FALSE, warning=FALSE, include=FALSE}
# Load needed modules
box::use(
    broom[augment, glance, tidy],
    correlation[cor_test],
    corrr[correlate],
    DataExplorer[plot_histogram],
    dplyr[
        arrange, 
        case_when, 
        desc, 
        filter, 
        full_join,
        left_join,
        mutate, 
        percent_rank, 
        relocate, 
        select
    ],
    effectsize[standardize_parameters],
    ggplot2[aes, geom_point, ggplot],
    insight[get_predicted],
    magrittr[`%>%`, `%T>%`],
    MASS[glm.nb],
    parameters[select_parameters, parameters],
    performance[
        check_model,
        compare_performance, 
        print_html, 
        test_performance
    ],
    purrr[map],
    readxl[read_xlsx],
    recipes[
        add_role, 
        all_numeric_predictors, 
        bake, 
        prep, 
        recipe, 
        step_center, 
        step_mutate,
        step_normalize,
        update_role
    ],
    sids_data_wrangling = ./modules/sids_data_wrangling,
    sids_model_performance = ./modules/sids_model_performance,
    janitor[clean_names, tabyl],
    tibble[as_tibble, tibble],
    tmap[tmap_mode, tm_polygons, tm_shape]
)
```

# Import the data:

```{r}
raw <- 
    # Parse excel file
    read_xlsx("data/finaldataforanalysis3_220121.xlsx") %>%
    # Clean up variability in naming conventions
    clean_names()
```

## Get census tract populations and spatial features:

```{r}

## This is a custom function I wrote that pulls data from the TidyCensus API about
## population count of people under five years old and about spatial features 
## for each census tract. I have commented it out and saved the result in an RDS file
## so as to not make a new call to the API every time this script is run. You can
## inspect the function definition in the modules folder of the source code.

# coords_and_pop_est <- 
#     sids_data_wrangling$get_coords_and_pop_est(raw)
# 
# saveRDS(coords_and_pop_est, "data/coords_and_pop_est.RDS")

coords_and_pop_est <- readRDS("data/coords_and_pop_est.RDS")

# Join the population counts to the imported dataframe
df <- 
    coords_and_pop_est %>%
    # Convert to tibble format
    as_tibble() %>%
    # Drop spatial features
    select(-geometry) %>%
    # And join to raw
    full_join(raw)
```

# Initial Data Exploration

## Summarize and visualize the primary outcome:

`count_asphyxia` = the count of SIDS-related deaths in each census tract

This is a count-type outcome, which is typically modeled using the Poisson or Negative Binomial distributions. I will be using the Negative Binomial, since the Poisson is limited by having its variance needing to be equal to its mean. 

Here we will visualize the `count_asphyxia` distribution of count frequencies.

```{r}
plot_histogram(df$count_asphyxia)
```

As expected, the majority of census tracts do not have any SIDS-related deaths.

It's a little hard to see the tail of the distribution so let's tabulate:

```{r}
tabyl(df$count_asphyxia)
```

## Visualize the outcome on a map:

Here we will take a different tact and visualize the geographic distribution of `count_asphyxia`. Any census tract with at least one death will show up on the map, with darker colors representing higher counts.

```{r}
tmap_mode("view")

tm_shape(
    (coords_and_pop_est %>%
         full_join(df) %>%
         select(fips, count_asphyxia) %>%
         filter(count_asphyxia > 0)
    )) +
    tm_polygons(
        "count_asphyxia", 
        palette = "-magma",
        alpha = 0.70
    )
```



A lot of the census tracts with elevated death counts are concentrated on the South and West sides of the county.

## Predictor Selection

In the sections that follow, I will show my process for selecting which predictor variables will included in the model. At baseline, all models will contain the outcome variable `count_asphyxia` and the variable `pop_under_five`.

`pop_under_five` = The population of people under age five in each census tract.

Including `pop_under_five` in the model will help account for variation in the relative amounts of young children in each tract and how that relates to the number of SIDS-related deaths we predict to be present.

### Explore correlations

When choosing predictors for our model, we want variables that are as highly correlated with `count_asphyxia` as possible, while minimizing the potential for [multicollinearity](https://www.statology.org/multicollinearity-regression/).

Let's start by generating a correlation matrix and filtering for variables that have at least a weak association (> 0.20) with `count_asphyxia`:

```{r}
sids_correlations <- 
    df %>%
    select(-fips) %>%
    relocate(count_asphyxia, .before = pop_under_five) %>%
    correlate() %>%
    filter(abs(count_asphyxia) > 0.20) %>%
    arrange(desc(abs(count_asphyxia)))

sids_correlations
```

`publicinsurance` has (just barely) the strongest correlation with `count_asphyxia`. 

`publicinsurance` = The percentage of residents in each census tract who are on public insurance

Let's visualize the relationship:

```{r}
plot(cor_test(df, "count_asphyxia", "publicinsurance"))
```

In order to minimize multicollinearity with additional predictor variables, let's select for variables that still have some degree of correlation with `count_asphyxia`, but have no more than weak correlation (< 0.5) with `publicinsurance`:

```{r}
sids_correlations %>%
    filter(abs(count_asphyxia) > 0.20) %>%
    filter(abs(publicinsurance) < 0.5)
```

This just leaves `count_opioid_death`.

`count_opioid_death` = count of opioid-related deaths in each census tract.

```{r}
plot(cor_test(df, "count_asphyxia", "count_opioid_death"))
```

There's a large outlier of many opioid deaths in an area with no asphyxiation deaths, but otherwise, there does seem to be a positive trend.

To fill out our modeling, we will try another four variables that correlate with `count_asphyxia`. These being `white`, `svi_household_composition_disability`, `incomegt75`, and `pe_marriedfemales`. I left out `black` and `privateinsurance` because these are definitely co-linear with `white` and `publicinsurance` respectively.

`white` = The percentage of residents in each census tract who identify their race as White 

`svi_household_composition_disability` = Percentile ranking for each census tract on the [Social Vulnerability Index](https://www.atsdr.cdc.gov/placeandhealth/svi/documentation/pdf/SVI2018Documentation_01192022_1.pdf) for Household Composition & Disability, which is a mash-up of information about households that include people older than 65, people younger than 17, people with disabilities, and/or single-parents

`incomegt75` = The percentage of residents in each census tract whose income are greater than the 75th percentile

`pe_marriedfemales` = The percentage of female residents that are married in each census tract

Here are the summary statistics and visualized distributions of our candidate predictors:

```{r}
df %>%
    select(
        pop_under_five,
        publicinsurance,
        count_opioid_death,
        white,
        svi_household_composition_disability,
        incomegt75,
        pe_marriedfemales
    ) %T>%
    plot_histogram() %>%
    summary()
    
```

# Pre-Processing

Now that we have our candidate predictors and outcome selected, we'll determine if our data needs any pre-processing before using it to fit models.

[Appendix A](https://www.tmwr.org/pre-proc-table.html) of @kuhnTidyModeling provides guidance for which types of pre-processing are useful for different types of models. It does not specifically name Negative Binomial models, but its suggestions for Poisson models are dummy variable generation, removal of columns with single unique values, and imputation for missing data, de-correlation. 

None of these steps are necessary for our data set. Because we do not have categorical predictors, we do not need to perform dummy variable generation or removal of columns with single unique values. Because we do not have any missing data, we do not need to perform imputation. We have done our best to minimize multi-collinearity, but will not go as far as [dimensionality reduction](https://blog.dataiku.com/dimensionality-reduction-how-it-works-in-plain-english) since we want to retain the original variables for use in interpretation of the model. 

# Model Development

## Formula Permutations

### Main Effects

The next step in modeling will be to finalize our selection of predictors from the short-list of candidates identified earlier. 

To automate the process we will make a nested list of formulas for predictor variables of interest. We'll apply each of those formulas to a negative binomial model function, then compare performance metrics for each of the permutations.

```{r}
# List out nested permutations of the models
nb_main_effects_models <-
    list(
        one_var = 
            glm.nb(
                count_asphyxia ~ pop_under_five,
                data = df
            ),
        two_var = 
            glm.nb(
                count_asphyxia ~ pop_under_five + publicinsurance,
                data = df
            ),
        three_var = 
            glm.nb(
                count_asphyxia ~ pop_under_five + publicinsurance + count_opioid_death,
                data = df
            ),
        four_var = 
            glm.nb(
                count_asphyxia ~ pop_under_five + publicinsurance + count_opioid_death + black,
                data = df
            ),
        five_var = 
            glm.nb(
                count_asphyxia ~ pop_under_five + publicinsurance + count_opioid_death + white + svi_household_composition_disability,
                data = df
            ),
        six_var = 
            glm.nb(
                count_asphyxia ~ pop_under_five + publicinsurance + count_opioid_death + white + svi_household_composition_disability + incomegt75,
                data = df
            ),
        seven_var = 
            glm.nb(
                count_asphyxia ~ pop_under_five + publicinsurance + count_opioid_death + white + svi_household_composition_disability + incomegt75 + pe_marriedfemales,
                data = df
            )
    )

# Compare performance metrics for the models
compare_performance(nb_main_effects_models, rank = TRUE) %>% print_html()
```


The performance package automatically decides which performance metrics to compute based on the type of model its given. If you set the rank option as TRUE like I have, it will also rank the models based on a composite score of performance metrics. Eye-balling the results, its selection of the four-predictor model seems sensible given that it is tied for best Nagelkerke's R^2 value (explained variation), has comparable RMSE (precision), and the most weight for both AIC and BIC metrics (goodness of fit estimates for out-of-sample predictions).

Let's check out info about the predictor parameters.

```{r}
parameters(nb_main_effects_models$four_var, exponentiate = TRUE)
```
All of the predictors are statistically significant on the Wald test, but its hard to interpret their effect sizes using each variable's raw units. Let's try evaluating when the predictor variables are standardized to have means of zero and standard deviations of one.

```{r}
standardize_parameters(nb_main_effects_models$four_var, exponentiate = TRUE)
```
All these incident rate ratios are sizable and in the expected directions. 

### Interaction Terms

Next we will assess whether it's helpful to add interaction terms. 

The {parameters} package has an algorithm for automatically checking which predictors are useful to include in the model. Let's see what it chooses when generating every possible interaction term as a candidate.

```{r}
nb_with_auto_selected_interacts <-
    glm.nb(
        count_asphyxia ~ (pop_under_five + publicinsurance + count_opioid_death + white)^2,
        data = df
    ) %>% select_parameters()

# Generate a table of the model parameters
parameters(nb_with_auto_selected_interacts, exponentiate = TRUE)
```

The algorithm has retained all main effect terms and suggests we should include interaction terms for `count_opioid_death` * `white` and `publicinsurance` * `white`. It is feasible to think that the amount of white people in a census tract would modulate the association of the count of opioid deaths and the amount of public insurance holders with the outcome. That said, the absolute coefficient for `publicinsurance` * `white` is small and it's p-value is non-significant. 

Let's compare performance for this model against the main effects model and a model with just the `count_opioid_death` * `white` term.

```{r}
nb_with_one_interact <-
    glm.nb(
        count_asphyxia ~ pop_under_five + publicinsurance + count_opioid_death + white + count_opioid_death:white,
        data = df
    )

compare_performance(
    just_main_effects = nb_main_effects_models$four_var, 
    one_interact = nb_with_one_interact, 
    two_interacts = nb_with_auto_selected_interacts,
    rank = TRUE
) %>% print_html()
```
At first blush, the table says using both interaction terms makes the best model, but the differences between the actual metrics seem negligible. Let's do a formal test for difference between the models.

```{r}
test_performance(
    nb_main_effects_models$four_var, 
    nb_with_one_interact, 
    nb_with_auto_selected_interacts
) 
```
Consistent with our intuition, the observed data are computed as 57 time more probable for the model with one interaction term compared to the main effects model, but there is no boost in probability from adding a second interaction term. 

Here are the estimated standardized effect sizes for terms in our final negative binomial model:

```{r}
# Show parameter effect size estimates
standardize_parameters(nb_with_one_interact, exponentiate = TRUE)
```


```{r}
standardize_parameters(nb_main_effects_models$four_var, exponentiate = TRUE)
```
```{r}
parameters(nb_main_effects_models$four_var, exponentiate = TRUE)
```
```{r}
sids_model_performance$make_rootogram(nb_main_effects_models$four_var)
```


# Model Assessment

## Visually assessing the model fit

So far, we've been using performance metrics to assess fit, but now let's visualize the fit as well. We'll use a "[hanging rootogram](https://datavizproject.com/data-type/rootogram/)". Let's break down the components of a rootogram:

1. The red curve with dots represents the model's expected frequency for each count value.
2. The bars represents the observed frequency for each count value.
3. In this visualization, we imagine that we are pinning the top of each bar (observed frequency) to the corresponding dot on the red curve (expected frequency).
4. If a bar hangs from the pin all the way down to the x-axis (zero on the y-axis), that means that there is no difference between the expected and observed frequencies for that count value (perfect prediction).
5. If a bar hangs below the x-axis, the model underestimated the expected frequency for that count value. Conversely, if a bar hangs above the x-axis, the model over-estimated.

This would be a perfect model for our observed counts:

```{r}
perfect_model <- tibble(
    .obs = df$count_asphyxia,
    .pred = df$count_asphyxia
)

sids_model_performance$make_rootogram(perfect_model)
```

And this is what our negative binomial model looks like:

```{r}
sids_model_performance$make_rootogram(nb_with_one_interact)
```

The rootogram tells us that that the model is slightly over-predicting the frequency of low counts (0-1) and unable to predict counts over 2.

## Mapping the residuals

```{r}
tm_shape(
    coords_and_pop_est %>%
        full_join(df) %>%
        full_join(
            augment(
                nb_with_one_interact, 
                type.residuals = "pearson")
        ) %>%
        select(fips, .std.resid) %>%
        mutate(.std.resid = -1 * .std.resid) %>%
        filter(abs(.std.resid) > 1)
    ) +
    tm_polygons(
        ".std.resid", 
        palette = "Spectral",
        alpha = 0.7
    )
```

